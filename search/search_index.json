{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Here shall lie miscellaneous things...</p>"},{"location":"Python/Benefiting_From_Threading_in_Spite_of_the_GIL_in_Python/","title":"Benefiting From Threading in Spite of the GIL in Python","text":"<p>As many people use Python on a daily basis, I thought I'd share something that interested me for quite some time, and very recently I finally took initiative to get to the bottom of.</p> <p>Disclaimer</p> <p>This isn't about best practices or common use-cases, it's a bit deeper dive, to those who take interest in Python and its internals (very deep internals) and care about how and why.</p> <p>If it's not very interesting to you, it's totally cool, you can stop here, <code>exit()</code>.</p>"},{"location":"Python/Benefiting_From_Threading_in_Spite_of_the_GIL_in_Python/#the-scope","title":"The Scope","text":"<p>The most wide-spread implementation of Python is CPython (written in C, duh), it's open-source, and here's the repo: python/cpython. That's where my research took place.</p> <p>Note that currently Python 3.13 is underway (this document is written over CPython with the commit SHA of 557b05c), and for persistence the links are in relation to that specific commit, implementation may vary (greatly) with time, so the specifics and possible change between versions are omitted, as this document is powered by curiosity alone.</p>"},{"location":"Python/Benefiting_From_Threading_in_Spite_of_the_GIL_in_Python/#threadsasyncio","title":"Threads/Asyncio","text":"<p>Python (currently) works with a single process that can share resources with multiple threads, it manages to do so with the GIL (Global Interpreter Lock), with each thread awaiting its turn (PEP 703 anyone?).</p> <p>Many of us have had some experience with async functions, especially in writing APIs or in the context of network interaction, and expect the speedup of using it in specific areas, like communication with remote servers, writing logs, etc.</p> <p>While threads and asyncio aren't the same thing, both have ways of improving performance in certain areas, by allowing other tasks to execute at the same time for specific operations.</p> <p>This may raise a few questions, like \"Why do we get a speedup there?\" or \"How does Python know where to release the GIL, and let other tasks resume?\".</p>"},{"location":"Python/Benefiting_From_Threading_in_Spite_of_the_GIL_in_Python/#under-the-hood","title":"Under The Hood","text":"<p>Well, there isn't such thing as magic (not if you go deep enough, which in some cases you simply shouldn't), so here's the process I went through to look for an answer.</p> <ol> <li> <p>I searched for something I know should have a blocking system call somewhere, like reading from a file, so naturally    I went to <code>Lib/pathlib.py</code>, and    specifically <code>pathlib.Path.read_bytes()</code>.    Which calls <code>pathlib.Path.open()</code>, which in turn calls <code>io.open()</code>, but looking at    <code>Lib/io.py</code> I couldn't    see anything useful, so at this point, from my experience with CPython, I know I needed to look for the C code which    actually performs the logic.</p> </li> <li> <p>Conveniently enough, I found <code>Modules/_io/fileio.c</code> and the function inside    it <code>_io_FileIO_read_impl</code>,    which in turn    calls <code>_Py_read</code>,    and inside this function I stumbled upon something interesting...</p> </li> <li> Python/fileutils.c<pre><code>Py_ssize_t\n_Py_read(int fd, void *buf, size_t count)\n{\nPy_ssize_t n;\nint err;\nint async_err = 0;\nassert(PyGILState_Check());\n/* _Py_read() must not be called with an exception set, otherwise the\n     * caller may think that read() was interrupted by a signal and the signal\n     * handler raised an exception. */\nassert(!PyErr_Occurred());\nif (count &gt; _PY_READ_MAX) {\ncount = _PY_READ_MAX;\n}\n_Py_BEGIN_SUPPRESS_IPH\ndo {\nPy_BEGIN_ALLOW_THREADS\nerrno = 0;\n#ifdef MS_WINDOWS\n_doserrno = 0;\nn = read(fd, buf, (int)count);\n// read() on a non-blocking empty pipe fails with EINVAL, which is\n// mapped from the Windows error code ERROR_NO_DATA.\nif (n &lt; 0 &amp;&amp; errno == EINVAL) {\nif (_doserrno == ERROR_NO_DATA) {\nerrno = EAGAIN;\n}\n}\n#else\nn = read(fd, buf, count);\n#endif\n/* save/restore errno because PyErr_CheckSignals()\n         * and PyErr_SetFromErrno() can modify it */\nerr = errno;\nPy_END_ALLOW_THREADS\n} while (n &lt; 0 &amp;&amp; err == EINTR &amp;&amp;\n!(async_err = PyErr_CheckSignals()));\n_Py_END_SUPPRESS_IPH\nif (async_err) {\n/* read() was interrupted by a signal (failed with EINTR)\n         * and the Python signal handler raised an exception */\nerrno = err;\nassert(errno == EINTR &amp;&amp; PyErr_Occurred());\nreturn -1;\n}\nif (n &lt; 0) {\nPyErr_SetFromErrno(PyExc_OSError);\nerrno = err;\nreturn -1;\n}\nreturn n;\n}\n</code></pre> </li> <li> <p>In lines 1866 and 1884 (highlighted) of the snippet above we see these two suspicious macros:    <code>Py_BEGIN_ALLOW_THREADS</code> and <code>Py_END_ALLOW_THREADS</code> respectively, so I looked for where they're defined, which was    <code>Include/ceval.h</code>,    and above these functions the documentation says:</p> Include/ceval.h<pre><code>/* Interface for threads.\n   A module that plans to do a blocking system call (or something else\n   that lasts a long time and doesn't touch Python data) can allow other\n   threads to run as follows:\n   ...preparations here...\n   Py_BEGIN_ALLOW_THREADS\n   ...blocking system call here...\n   Py_END_ALLOW_THREADS\n   ...interpret result here...\n...\n</code></pre> </li> <li> <p>So it seemed I found what I was looking for, these two macros define the start and end of a blocking system call, and    code written between these can benefit our async Python code.    And indeed, between these macros in lines 1870 and 1879 (also highlighted) of the snippet above lies the    syscall read.</p> </li> <li> <p>I admit I did not really go deeper than this, below these macros are the C functions implementation and usage of    internal CPython structures, so this is as far as this specific journey went.</p> </li> </ol>"},{"location":"Python/Benefiting_From_Threading_in_Spite_of_the_GIL_in_Python/#verifying-the-theory","title":"Verifying The Theory","text":"<p>I wanted to make sure I was right, and wanted to see another example of it in a different context where it makes sense, and so I searched for these macros in CPython, and found them being used in <code>Modules/socketmodule.c</code> inside the function <code>sock_call_ex</code> (call ex, hehe...), which after some looking at the code seemed to be called with many socket related syscalls: <code>accept</code>, <code>connect</code>, <code>send</code>, <code>recv</code>, and more.</p> <p>This was indeed reassuring of the theory above, and I concluded my research happily.</p>"},{"location":"Python/Benefiting_From_Threading_in_Spite_of_the_GIL_in_Python/#myth-busting","title":"Myth-Busting","text":"<p>Calling C code (or any other language) from Python does not guarantee concurrency, as written in Python's code about the GIL: \"The mechanism used by the CPython interpreter to assure that only one thread executes Python bytecode at a time\".</p> <p>The purpose is to protect Python data from being modified by several threads simultaneously, meaning that the release of the GIL needs to be explicit, and of course, with much caution.</p>"},{"location":"Python/Benefiting_From_Threading_in_Spite_of_the_GIL_in_Python/#bonus","title":"Bonus","text":"<p>In <code>Include/ceval.h</code> the macros were defined as:</p> Include/ceval.h<pre><code>PyAPI_FUNC(PyThreadState *) PyEval_SaveThread(void);\nPyAPI_FUNC(void) PyEval_RestoreThread(PyThreadState *);\nPyAPI_FUNC(void) PyEval_AcquireThread(PyThreadState *tstate);\nPyAPI_FUNC(void) PyEval_ReleaseThread(PyThreadState *tstate);\n#define Py_BEGIN_ALLOW_THREADS { \\\n                 PyThreadState *_save; \\\n                 _save = PyEval_SaveThread();\n#define Py_BLOCK_THREADS      PyEval_RestoreThread(_save);\n#define Py_UNBLOCK_THREADS     _save = PyEval_SaveThread();\n#define Py_END_ALLOW_THREADS   PyEval_RestoreThread(_save); \\\n            }\n</code></pre> <p>I took a peek at <code>PyEval_SaveThread</code>, which I found in <code>Python/ceval_gil.c</code>, and there I saw:</p> Python/ceval_gil.c<pre><code>PyThreadState *\nPyEval_SaveThread(void)\n{\nPyThreadState *tstate = _PyThreadState_SwapNoGIL(NULL);\n_Py_EnsureTstateNotNULL(tstate);\nstruct _ceval_state *ceval = &amp;tstate-&gt;interp-&gt;ceval;\nassert(gil_created(ceval-&gt;gil));\ndrop_gil(ceval, tstate);\nreturn tstate;\n}\n</code></pre> <p>This gave me a glance at the existence of functions like <code>drop_gil</code>, <code>gil_created</code>, <code>destroy_gil</code>, and <code>take_gil</code>. All there in that file.</p> <p>So if anyone wants to go even deeper, here's where you can continue from.</p>"},{"location":"Python/Benefiting_From_Threading_in_Spite_of_the_GIL_in_Python/#conclusion","title":"Conclusion","text":"<p>I like looking inside Python and see how it works. For me, it was a very interesting research, and I hope it was interesting to you as well.</p> <p>Quote</p> <p>\"There's no such thing as magic!\" - Vernon Dursley, Harry Potter.</p>"}]}